#!/usr/bin/env python3.8
import tempfile
import argparse
import sys
import enum 
import time
import os
import sqlite3
import hashlib
import json
from reprint import output

mstime = lambda: int(round(time.time() * 1000))
#########################################################################################################
class StrUtils:
  @staticmethod
  def convert_bytes(num) -> str:
    for x in ['B', 'KB', 'MB', 'GB', 'TB']:
      if num < 1024.0:
        return "%3.1f%s" % (num, x)
      num /= 1024.0

  @staticmethod
  def msToHours(num) -> str:
    ms = num % 1000
    s = (num // 1000) % 60
    m = (num // 60000)  % 60
    h = num // (60 * 60 * 1000)
    return "%dh %dm %ds %03dms" % (h, m, s, ms)

  @staticmethod
  def secondsToHours(num) -> str:
    s = num % 60
    m = (num // 60)  % 60
    h = num // 3600
    return "%dh %dm %ds" % (h, m, s)
#########################################################################################################

class HasherFactory:
  @staticmethod
  def createHasher():
    return hashlib.sha512()

#########################################################################################################

class HTMLGenerator:
  def __init__(self):
    pass


class DBEngine:
  def __init__(self):
    self.connection = None
    self.cursor = None
    self.path = ""

  def open(self, path:str):
    self.path = path
    self.connection = sqlite3.connect(path)
    self.cursor = self.connection.cursor()
    self.makeDb()

  def checkDb(self):
    if not self.cursor or not self.connection:
      raise Exception('dbEngine', 'not opened')

  def makeDb(self):
    self.checkDb()
    self.cursor.execute("""
      CREATE TABLE 'files' (
        'path' TEXT NOT NULL UNIQUE,
        'hash'  TEXT NOT NULL,
        'size' INTEGER NOT NULL);
    """)
    self.cursor.execute("""
      CREATE TABLE 'result' (
      'groupId' TEXT NOT NULL,
      'path'  TEXT NOT NULL,
      'size'  INTEGER NOT NULL);
    """)

    self.cursor.execute("""CREATE INDEX 'hash_i' ON 'files' ('hash');""")
    self.connection.commit()

  def close(self):
    self.cursor = None
    if self.connection:
      self.connection.close()
    self.connection = None

  def notUniqueHashes(self):
    self.checkDb()
    rc = []
    for row in self.cursor.execute("SELECT DISTINCT hash FROM files GROUP BY hash HAVING COUNT(*) > 1"):
      rc.append(row[0])
    return rc

  def filesByHash(self, hash: str):
    self.checkDb()
    rc = []
    for row in self.cursor.execute("SELECT path, size FROM files  WHERE hash='" + hash + "';"):
      rc.append((row[0], row[1]))
    return rc

  def writeFileInfo(self, path: str, hash: str, size: int):
    self.checkDb()
    self.cursor.execute("INSERT INTO files VALUES (?,?,?)", (path, hash, size))
    self.connection.commit()

  def writeGroupRecord(self, hash: str, fname: str, size: int):
    self.checkDb()
    self.cursor.execute("INSERT INTO result VALUES (?,?,?)", (hash, fname, size))
    self.connection.commit()

#########################################################################################################

class Stats:
  def __init__(self):
    self.totalCount = 0
    self.totalSize = 0
    self.startTime = mstime()
    self.filesCount = 0
    self.filesSize = 0

#########################################################################################################

class LoggerMode(enum.Enum):
  verboseMode = 0
  quietMode = 1
  progressAndErrors = 2
  progressVerbose = 3

class Logger:
  def __init__(self, mode: LoggerMode, seed: str):
    self.printMode = mode
    self.stats = Stats()
    self.hashIndex = 0
    self.progressOutputLine = None
    self.progressPanelLinesCount = 4
    self.logfile = None
    self.seed = seed
    self.createLogfile()

  def createLogfile(self):
    if not self.seed:
      self.seed = str(mstime())
    logFileName = "./dry.%s.log" % (seed)
    self.logfile = open(logFileName, 'a')
    self.logfile.write("start dry " + str(mstime()))
    self.logfile.flush()

  def logFatal(self, msg):
      self.logError(msg)
      exit(1)

  def logError(self, msg):
      print(str(msg), file=sys.stderr)
      if self.logfile:
        self.logfile.write("[ERROR] %s \n" % str(msg))
        self.logfile.flush()

  def printIndexProgress(self, fname: str):
    if not self.progressOutputLine:
      self.logFatal("no progressOutputLine in printIndexProgress!")

    if self.printMode not in [LoggerMode.progressAndErrors, LoggerMode.progressVerbose]:
      return
    timediff = mstime() - self.stats.startTime
    self.progressOutputLine[1] = "Files %d of %d done (%s of %s)" % (self.stats.filesCount,
                                                            self.stats.totalCount,
                                                            StrUtils.convert_bytes(self.stats.filesSize),
                                                            StrUtils.convert_bytes(self.stats.totalSize))
    self.progressOutputLine[2] = "duration: %s" % (StrUtils.msToHours(timediff))
    self.saveOutputLines()

  def saveOutputLines(self):
    if self.logfile:
      self.logfile.write("progress:\n")
      for line in self.progressOutputLine:
        self.logfile.write(line + "\n")
      self.logfile.flush()

  def printReduceProgress(self, hash, totalCount):
    if not self.progressOutputLine:
      self.logFatal("no progressOutputLine in printIndexProgress!")
    if self.printMode not in [LoggerMode.progressAndErrors, LoggerMode.progressVerbose]:
      return

    timediff = mstime() - self.stats.startTime
    self.progressOutputLine[1] = "[{%d} of {%d}] {%s}" % (self.hashIndex, totalCount, hash)
    self.progressOutputLine[2] = "duration: %s" % (StrUtils.msToHours(timediff))
    self.saveOutputLines()

  def verboseLog(self, msg):
    if self.printMode in [LoggerMode.verboseMode, LoggerMode.progressVerbose]:
      print(msg)
    if self.logfile:
      self.logfile.write(str(msg))
      self.logfile.flush()

  def log(self, msg):
    if self.printMode != LoggerMode.quietMode:
      print(msg)
    if self.logfile:
      self.logfile.write(str(msg))
      self.logfile.flush()

#########################################################################################################

class Formats(enum.Enum):
  json = 0
  stdout = 1
  ##html = 1
  sqlite = 2
  invalid = 3

  @staticmethod
  def parce(value) -> enum.Enum:
      if value == None:
        return Formats.invalid
      for m, mm in Formats.__members__.items():
        if m == value.lower():
          return mm
      return Formats.invalid

  @staticmethod
  def ext(val) -> str:
      extentions = {
        Formats.json: ".json",
        Formats.stdout: ".txt",
##        Formats.html: ".htm",
        Formats.sqlite: ".sqlite"
      }
      if val != Formats.invalid:
        return extentions[val]
      print("invalid format" + val.name)
      return ""
    
#########################################################################################################

class FolderProcessor:
  def __init__(self, logger: Logger, args, seed: str):
    self.logger = logger
    self.dbEngine = DBEngine()
    self.dbPath = ":memory:"
    self.fmt = Formats.parce(args.format)
    self.comparatorBlockSize = 10240 #10k
    self.seed = seed
    if not seed:
      self.seed = mstime()

    if self.fmt == Formats.invalid:
        logger.logError("invalid format " + args.format)
        parser.print_help(sys.stderr)
        sys.exit(1)

    self.inPath = args.path
    if not os.path.isdir(self.inPath):
        logger.logError("input must be a folder")
        parser.print_help(sys.stderr)
        sys.exit(1)
    self.compareContent = args.compare

    #if Logger.progressPrint:
    #  progressOutput = output(output_type="list", initial_len=1, interval=0)
    #else:
    # progressOutput = None
    self.target = args.target
    if not self.target:
      self.target = "."
    if os.path.isdir(self.target):
      self.target += "/duplicatesReport.%s.%s" % (seed, Formats.ext(self.fmt))
    if self.fmt == Formats.sqlite and self.target:
      self.dbPath = self.target
    self.logger.verboseLog("in: %s, out[%s]: %s" %  (self.inPath, args.format, self.target))

  def calc(self, fname: str) -> str:
    hasher = HasherFactory.createHasher()
    block_size = 128 * hasher.block_size
    a_file = open(fname, 'rb')
    chunk = a_file.read(block_size)
    processedSize = block_size
    fSize = os.path.getsize(fname)
    self.logger.progressOutputLine[3] = ""
    if fSize <= 0:
      return hasher.hexdigest()
    while chunk:
      prc = (processedSize / fSize) * 100.0
      self.logger.progressOutputLine[3] = "process file %s %0.3f%%" % (fname, prc)
      hasher.update(chunk)
      chunk = a_file.read(block_size)
      processedSize += block_size
    a_file.close()
    self.logger.progressOutputLine[3] = ""
    return hasher.hexdigest()

  def compareFiles(self, path1: str, path2: str) -> bool:
    self.logger.log("compare " + path1 + " -> " + path2)
    if not os.path.isfile(path1) or not os.path.isfile(path2):
      raise Exception('compareFiles', 'not a file')
    if path1 == path2:
      return True
    if os.path.getsize(path1) != os.path.getsize(path2):
      self.logger.log("different sizes")
      return False
    f1 = open(path1, 'rb')
    f2 = open(path2, 'rb')
    chunkIndex = 0
    chunk1 = f1.read(self.comparatorBlockSize)
    chunk2 = f2.read(self.comparatorBlockSize)
    while chunk1 and chunk2:
      if chunk1 != chunk2:
        self.logger.log("different chunk[" + str(chunkIndex) + "]")
        f1.close
        f2.close
        return False
      chunkIndex += 1
      chunk1 = f1.read(self.comparatorBlockSize)
      chunk2 = f2.read(self.comparatorBlockSize)
    return True

  def readFile(self, path: str):
    self.logger.verboseLog("read file " + path)
    try:
      hashStr = self.calc(path)
      fileSize = os.path.getsize(path)
    except KeyboardInterrupt:
      self.logger.log("Interrupted")
      exit(-1)
    except Exception as e:
      self.logger.logError("cannot read file %s  exception: %s" % (path, str(e)))
    self.logger.stats.filesCount += 1
    self.logger.stats.filesSize += fileSize
    self.logger.printIndexProgress(path)
    self.logger.verboseLog("hash: %s size: %d" % (hashStr, fileSize))
    self.dbEngine.writeFileInfo(path, hashStr, fileSize)
  
  def readDir(self, path: str):
    try:
      if os.path.islink(path): 
        self.logger.verboseLog("ignore link " + path)
        return
      if os.path.isfile(path):
        self.readFile(path)
        return
      if os.path.isdir(path):
        self.logger.verboseLog("read folder " + path)
        for entry in os.listdir(path):
          self.readDir(path + "/" + entry)
    except KeyboardInterrupt:
      self.logger.log("Interrupted")
      exit(-1)
    #except Exception as e:
      #self.logger.logError("cannot process folder %s. skip. exception: %s" % (path, str(e)))

  def groupRecords(self):
    groups = {}
    nuHashes = self.dbEngine.notUniqueHashes()
    for hash in nuHashes:
      self.logger.verboseLog(hash + " :: " + str(self.dbEngine.filesByHash(hash)))
      self.logger.hashIndex += 1
      self.logger.printReduceProgress(hash, len(nuHashes))
      files = self.dbEngine.filesByHash(hash)
      if len(files) <= 1:
        continue
      groups[hash] = {}
      originalFile = files[0]
      groups[hash]["path"] = originalFile[0]
      groups[hash]["size"] = originalFile[1]
      self.dbEngine.writeGroupRecord(hash, originalFile[0], originalFile[1])
      for secondFile in files[1:]:
        if (not self.compareContent) or self.compareFiles(originalFile[0], secondFile[0]):
          groups[hash]["path"] = secondFile[0]
          groups[hash]["size"] = secondFile[1]
          self.dbEngine.writeGroupRecord(hash, secondFile[0], secondFile[1])
    return groups

  def scandir(self, path: str):
    try:
      if os.path.islink(path):
        return
      if os.path.isdir(path):
        for entry in os.listdir(path):
          self.scandir(path + "/" + entry)
      else:
        self.logger.stats.totalSize += os.path.getsize(path)
        self.logger.stats.totalCount += 1
    except KeyboardInterrupt:
      exit(-1)
    except Exception as e:
      self.logger.logError("cannot scan %s. error: %s" % (path, str(e)))

  def prescan(self):
    if not self.inPath:
      self.logger.logFatal("no input path")
    self.scandir(self.inPath)
    self.logger.verboseLog("prescan stage: done. found %d files (%s)" % (self.logger.stats.totalCount, StrUtils.convert_bytes(self.logger.stats.totalSize))) 

  def exec(self):
    with output(output_type="list", initial_len=self.logger.progressPanelLinesCount, interval = 0) as self.logger.progressOutputLine:
      if not self.logger.progressOutputLine:
        self.logger.logFatal("exec: outLine is not setted ")
      self.dbEngine.open(self.dbPath)
      self.logger.progressOutputLine[0] = "----[   indexing stage  ]----"
      self.readDir(self.inPath)
      self.logger.verboseLog("indexing stage: done")
      self.logger.progressOutputLine[0] = "----[ comparation stage ]----"
      groups = self.groupRecords()
      self.logger.verboseLog("comparation stage: done")
      groups_json = json.dumps(groups, sort_keys = True, indent = 2, separators = (',', ': '))
      if self.fmt == Formats.json:
        outFile = open(self.target, 'w')
        outFile.write(groups_json)
        outFile.close()
      elif self.fmt == Formats.stdout:
        print(groups_json)
      else:
        self.logger.log("database saved to " + self.dbPath)
      self.logger.progressOutputLine[0] = "----[ done ]----"
      self.dbEngine.close()

parser = argparse.ArgumentParser(add_help=True, description="Duplicates detector [Don't repeat yourself!]")
parser.add_argument("-o", "--target", "--out", action="store", default=".", help="output target (default .)")
parser.add_argument("-f", "--format", "--fmt", action="store", default=Formats.sqlite.name, help="output format <json|stdout|sqlite(default)")
parser.add_argument("-v", "--verbose", action="store_true", help="print all messages")
parser.add_argument("-q", "--quiet", action="store_true", help="no output")
parser.add_argument("-c", "--compare", action="store_true", help="content based comparation (hash based is default)")
parser.add_argument("--progress", action="store_true", help="print progress line")
parser.add_argument("path", help="folder to scan")
args = parser.parse_args()
seed = str(mstime())
lm = LoggerMode.verboseMode
if args.verbose and args.progress:
  loggerMode = LoggerMode.progressVerbose
elif args.progress:
  loggerMode = LoggerMode.progressAndErrors
elif args.verbose:
  loggerMode = LoggerMode.verboseMode
else:
  loggerMode = LoggerMode.quietMode
logger = Logger(loggerMode, seed)


executor = FolderProcessor(logger, args, seed)
executor.prescan()
executor.exec()